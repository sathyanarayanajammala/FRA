---
title: "FRA Assignment"
author: "Satya"
date: "August 7, 2017"
output: html_document
---

### Load libraries

```{r}

library(DMwR)
library(InformationValue)
library(ROCR)

```
### Read Test and Training Data

```{r}
setwd("H:\\GreatLakes\\off campus assignment\\off campus assignment")
traingsrcdata<-read.csv("training.csv")
testingsrcdata<-read.csv("test.csv")

trainingdata<-traingsrcdata
testdata<-testingsrcdata

```
### Clean the data. Out of 5000 records 142 are NA's in training data. so removing NA's
### Out of 1000 records 20 are NA's.in testing data. So removing NA's
```{r}
summary(trainingdata)
summary(testdata)
trainingdata<-na.omit(trainingdata)
testdata<-na.omit(testdata)


```
### Checking the data Issues
```{r}
trainingdata$Casenum<-NULL
testdata$Casenum<-NULL  
  table(trainingdata$SeriousDlqin2yrs)
  table(testdata$SeriousDlqin2yrs)

```
### Un balanced data is observed from above table
### using SMOTE we need to do the data balancing for train data
```{r}

trainingdata$SeriousDlqin2yrs<-as.factor(trainingdata$SeriousDlqin2yrs)
testdata$SeriousDlqin2yrs<-as.factor(testdata$SeriousDlqin2yrs)
trainingDataSMOTE<- SMOTE(SeriousDlqin2yrs~.,trainingdata,perc.over = 500)


```

### SMOTE Data Balance after executing SMOTE function

```{r}
table(trainingDataSMOTE$SeriousDlqin2yrs)


```

## Logistic regression Modeling
```{r}

logit<- glm(trainingDataSMOTE$SeriousDlqin2yrs~.,data = trainingDataSMOTE,family = binomial)

summary(logit)

```
### Make the preditcitons using predict function

```{r}
    
predictTestDataProbility<-predict(logit,newdata=testdata,type="response")

```
### Build the confusion Matrix
### Compare actual decisions with predictions
```{r}
    
optCutOff <- optimalCutoff(testdata$SeriousDlqin2yrs, predictTestDataProbility)[1] 

confusionMatrix <- confusionMatrix(testdata$SeriousDlqin2yrs,predictTestDataProbility,optCutOff)
confusionMatrix
    
    


```
### Miss Classification Error
```{r}
misClassError(testdata$SeriousDlqin2yrs, predictTestDataProbility, threshold = optCutOff)

```
#### Lower the misclassification error, the better is the model

### ROC
```{r}

plotROC(testdata$SeriousDlqin2yrs,predictTestDataProbility)

```

